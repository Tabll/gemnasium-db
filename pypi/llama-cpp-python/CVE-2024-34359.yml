---
identifier: "CVE-2024-34359"
identifiers:
- "CVE-2024-34359"
- "GHSA-56xg-wfcc-g829"
package_slug: "pypi/llama-cpp-python"
title: "llama-cpp-python vulnerable to Remote Code Execution by Server-Side Template
  Injection in Model Metadata"
description: "`llama-cpp-python` depends on class `Llama` in `llama.py` to load `.gguf`
  llama.cpp or Latency Machine Learning Models. The `__init__` constructor built in
  the `Llama` takes several parameters to configure the loading and running of the
  model. Other than `NUMA, LoRa settings`, `loading tokenizers,` and `hardware settings`,
  `__init__` also loads the `chat template` from targeted `.gguf` 's Metadata and
  furtherly parses it to `llama_chat_format.Jinja2ChatFormatter.to_chat_handler()`
  to construct the `self.chat_handler` for this model. Nevertheless, `Jinja2ChatFormatter`
  parse the `chat template` within the Metadate with sandbox-less `jinja2.Environment`,
  which is furthermore rendered in `__call__` to construct the `prompt` of interaction.
  This allows `jinja2` Server Side Template Injection which leads to RCE by a carefully
  constructed payload."
date: "2024-05-13"
pubdate: "2024-05-13"
affected_range: ">=0.2.30,<=0.2.71"
fixed_versions: []
affected_versions: "All versions starting from 0.2.30 up to 0.2.71"
not_impacted: ""
solution: "Unfortunately, there is no solution available yet."
urls:
- "https://nvd.nist.gov/vuln/detail/CVE-2024-34359"
- "https://github.com/advisories/GHSA-56xg-wfcc-g829"
- "https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829"
- "https://github.com/abetlen/llama-cpp-python"
cvss_v3: "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H"
uuid: "73020fda-2588-4aeb-9d1a-d06d53fa65a5"
cwe_ids:
- "CWE-76"
- "CWE-937"
- "CWE-1035"
