---
identifier: "CVE-2025-53002"
identifiers:
- "CVE-2025-53002"
- "GHSA-xj56-p8mm-qmxj"
package_slug: "pypi/llamafactory"
title: "LLaMA-Factory allows Code Injection through improper vhead_file safeguards"
description: "A critical remote code execution vulnerability was discovered during
  the Llama Factory training process. This vulnerability arises because the `vhead_file`
  is loaded without proper safeguards, allowing malicious attackers to execute arbitrary
  malicious code on the host system simply by passing a malicious `Checkpoint path`
  parameter through the `WebUI` interface. The attack is stealthy, as the victim remains
  unaware of the exploitation. The root cause is that the `vhead_file` argument is
  loaded without the secure parameter `weights_only=True`.\n\nNote: In torch versions
  <2.6, the default setting is `weights_only=False`, and Llama Factory's `setup.py`
  only requires `torch>=2.0.0`."
date: "2025-06-27"
pubdate: "2025-06-27"
affected_range: "<=0.9.3"
fixed_versions: []
affected_versions: "All versions up to 0.9.3"
not_impacted: ""
solution: "Unfortunately, there is no solution available yet."
urls:
- "https://nvd.nist.gov/vuln/detail/CVE-2025-53002"
- "https://github.com/advisories/GHSA-xj56-p8mm-qmxj"
- "https://github.com/hiyouga/LLaMA-Factory/security/advisories/GHSA-xj56-p8mm-qmxj"
- "https://github.com/hiyouga/LLaMA-Factory/commit/bb7bf51554d4ba8432333c35a5e3b52705955ede"
- "https://github.com/hiyouga/LLaMA-Factory"
cvss_v3: "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:H"
uuid: "c7895cb2-8362-409c-8c1c-b9c1a2e51492"
cwe_ids:
- "CWE-94"
- "CWE-937"
- "CWE-1035"
